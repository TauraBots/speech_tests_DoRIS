{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Google Sounds "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importa-se:**\n",
    "1. gTTS       - Text-to-Speech da Google\n",
    "2. pydub      - conversor de audio\n",
    "3. glob       - explorador de arquivos\n",
    "4. speech_rec - para testar o audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtts import gTTS\n",
    "import os\n",
    "from pydub import AudioSegment\n",
    "import glob\n",
    "\n",
    "import speech_recognition as sr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gera audios a partir da API da google, salva no disco em *.mp3*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "frases = [\n",
    "    # Comandos 1\n",
    "          'go to the kitchen',\n",
    "          'go to the bathroom',\n",
    "          'go to the bedroom',\n",
    "          'go to the living room',\n",
    "    \n",
    "    # Comandos 2\n",
    "          'get the chips',\n",
    "          'get the cereal box',\n",
    "          'get the bottle of water',\n",
    "          \n",
    "    # Replica\n",
    "          'did you say kitchen?',\n",
    "          'did you say bedroom?',\n",
    "          'did you say bathroom?',\n",
    "          'did you say living room?',\n",
    "    \n",
    "    # Afirmacao\n",
    "          'ok, I am going!',\n",
    "          'yes human',\n",
    "    \n",
    "    # Saudacao\n",
    "          'hey doris',\n",
    "    \n",
    "    # Saudacao Replica\n",
    "          'hi human',\n",
    "    \n",
    "    # rivalidade\n",
    "          'I will win this competition',\n",
    "    \n",
    "    # Questions in appendixes rulesbook\n",
    "        'Where is the shelf?',\n",
    "        'Where is the plant?',\n",
    "        'How many chairs are in the dining room?',\n",
    "    # Anwers in appendixes rulesbook\n",
    "        'The shelf is in the kitchen',\n",
    "        'The plant is in the living room',\n",
    "        'There are six chairs in the dining room',\n",
    "        'I don\\'t know answer this question'\n",
    "    ]\n",
    "\n",
    "for i, frase in enumerate(frases):\n",
    "    frases[i] = frase.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT ignored - go to the kitchen\n",
      "NOT ignored - go to the bathroom\n",
      "NOT ignored - go to the bedroom\n",
      "NOT ignored - go to the living room\n",
      "NOT ignored - get the chips\n",
      "NOT ignored - get the cereal box\n",
      "NOT ignored - get the bottle of water\n",
      "NOT ignored - did you say kitchen?\n",
      "NOT ignored - did you say bedroom?\n",
      "NOT ignored - did you say bathroom?\n",
      "NOT ignored - did you say living room?\n",
      "NOT ignored - ok, i am going!\n",
      "NOT ignored - yes human\n",
      "NOT ignored - hey doris\n",
      "NOT ignored - hi human\n",
      "NOT ignored - i will win this competition\n",
      "NOT ignored - where is the shelf?\n",
      "NOT ignored - where is the plant?\n",
      "NOT ignored - how many chairs are in the dining room?\n",
      "NOT ignored - the shelf is in the kitchen\n",
      "NOT ignored - the plant is in the living room\n",
      "NOT ignored - there are six chairs in the dining room\n",
      "NOT ignored - i don't know answer this question\n"
     ]
    }
   ],
   "source": [
    "filenames_mp3 = glob.glob(r'Área de Trabalho/test_gTTS/*.mp3')\n",
    "\n",
    "for frase in frases:\n",
    "    filename_tmp = r'test_gTTS/'+frase.lower().replace(' ', '_').replace('?', '')+'.mp3'\n",
    "    if filename_tmp not in filenames_mp3:\n",
    "        print('NOT ignored - %s' % frase)\n",
    "        tts = gTTS(text=frase, lang='en')\n",
    "        tts.save(filename_tmp)\n",
    "    else:\n",
    "        print(\"ignored - %s\" % frase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converte os arquivos *.mp3* anteriores para *.wav* por causa da biblio *speech_recognition*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames_wav = glob.glob(r'Área de Trabalho/test_gTTS/*.wav')\n",
    "for filename in filenames_wav:\n",
    "    filename_tmp = filename.replace('.mp3', '.wav')\n",
    "    if filename_tmp not in filenames_wav:\n",
    "        print('NOT ignored - %s' % filename_tmp)\n",
    "        segment = AudioSegment.from_mp3(filename)\n",
    "        segment.export(filename_tmp, format='wav')\n",
    "    else:\n",
    "        print(\"ignored - %s\" % filename_tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Armazena o caminho de cada arquivo *.wav*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames_wav = glob.glob(r'Área de Trabalho/test_gTTS/*.wav')\n",
    "filenames_sorted = sorted(filenames_wav)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importa os *.wav* para a Classe *AudioFile* da *speech_recognition*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "audiofiles = []\n",
    "\n",
    "for filename in filenames_sorted:\n",
    "    audiofiles.append(sr.AudioFile(filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atribui um *ecognizer*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = sr.Recognizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fima faz o *speech-to-text* usando **sphinx** a partir dos audios da API da Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "frases_sorted = sorted(frases)\n",
    "\n",
    "for audiofile, frase in zip(audiofiles, frases_sorted):\n",
    "    with audiofile as source:\n",
    "        audio_tmp = rec.record(source)\n",
    "        print('Origin: %s' % frase)\n",
    "        sphinx_tmp = rec.recognize_sphinx(audio_tmp)\n",
    "        print('Sphinx: %s' % sphinx_tmp)\n",
    "        google_tmp = rec.recognize_google(audio_tmp)\n",
    "        print('Google: %s\\n\\n' % google_tmp)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec.recognize_sphinx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reintrodução do pocketsphinx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pocketsphinx as ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "in method 'Jsgf_get_rule', argument 1 of type 'Jsgf *'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-7a21d8bbe06a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecognize_sphinx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_tmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrammar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'3407.dict'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/speech_recognition/__init__.py\u001b[0m in \u001b[0;36mrecognize_sphinx\u001b[0;34m(self, audio_data, language, keyword_entries, grammar, show_all)\u001b[0m\n\u001b[1;32m    784\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfsg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# create FSG grammar if not available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m                 \u001b[0mjsgf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJsgf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrammar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m                 \u001b[0mrule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjsgf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_rule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0}.{0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrammar_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    787\u001b[0m                 \u001b[0mfsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjsgf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_fsg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_logmath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mfsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwritefile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfsg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sphinxbase/sphinxbase.py\u001b[0m in \u001b[0;36mget_rule\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    541\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_rule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m         \u001b[0;34m\"\"\"get_rule(Jsgf self, char const * name) -> JsgfRule\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_sphinxbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJsgf_get_rule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: in method 'Jsgf_get_rule', argument 1 of type 'Jsgf *'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tiarles/.local/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: generator 'LiveSpeech.__iter__' raised StopIteration\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "for phrase in ps.LiveSpeech(dict='3407.dict'):\n",
    "    print(phrase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapeia microfones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "for index, name in enumerate(sr.Microphone.list_microphone_names()):\n",
    "    print(\"Microphone with name \\\"{1}\\\" found for `Microphone(device_index={0})`\".format(index, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mic = sr.Microphone(device_index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recording the sound via sr.Microfone ans with statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = sr.Recognizer()\n",
    "mic = sr.Microphone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mic as source:\n",
    "    rec.adjust_for_ambient_noise(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mic as source:\n",
    "    audio = rec.listen(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rec.recognize_google(audio))\n",
    "print(rec.recognize_sphinx(audio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('my_audio.speech', 'wb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(audio, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('my_audio.speech', 'rb')\n",
    "audio2 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio == audio2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio.get_flac_data() == audio2.get_flac_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista = ['carry_me', 'home', 'early']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyttsx\n",
    "import speech_recognition as sr\n",
    "import gtts\n",
    "import pyaudio\n",
    "import random,os\n",
    "\n",
    "engine = pyttsx.init()\n",
    "def listen():\n",
    "    r=sr.Recognizer()\n",
    "    \n",
    "    with sr.Microphone() as source:\n",
    "        a = r.listen(source)\n",
    "\n",
    "        try:\n",
    "            return r.recognize_google(a)\n",
    "            print (r)\n",
    "        except sr.UnknownValueError:\n",
    "            print('could not understand audio')\n",
    "\n",
    "        except sr.RequestError as e:\n",
    "            print(\"Recog Error: (0)\".format(e))\n",
    "        return \"\"\n",
    "\n",
    "    \n",
    "def online():\n",
    "    speak('yes')\n",
    "\n",
    "def onlie1():\n",
    "    speak('hi...i am soft....... your personnel assistant....')\n",
    "    \n",
    "def media():\n",
    "    f=random.choice(['that will be good for this time!!!!','thats a good choice!!!!','good choice!!!!!'])\n",
    "    speak(f)                               \n",
    "    speak('connecting to player')                 \n",
    "    os.system('starting wmplayer.exe')\n",
    "    speak('which song do you want to play')\n",
    "    os.startfile('C:/Users/AAKASH/Music/'+listen()+'.mp3')\n",
    "    speak('playing'+listen()+'for you')\n",
    "    \n",
    "def shutdown():\n",
    "    speak('ok')\n",
    "    speak('connecting to command prompt')\n",
    "    speak('shuttting down')\n",
    "    os.system('shutdown -s')\n",
    "    \n",
    "def restart():\n",
    "    speak('ok')\n",
    "    speak('closing all applications')\n",
    "    os.system('restart -r')\n",
    "    \n",
    "def gooffline():\n",
    "      speak('ok')\n",
    "      speak('closing all systems')\n",
    "      quit()           \n",
    "\n",
    "def speak(text):\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "    \n",
    "def getonline():\n",
    "    speak('ok')\n",
    "    os.system('start C:/Rainmeter.exe') \n",
    "    speak('starting systems')\n",
    "    speak('i am online')\n",
    "\n",
    "def mainfunction():\n",
    "    a = r.listen(source)\n",
    "    user = r.recognize_google(a)\n",
    "    \n",
    "    print(user)\n",
    "    \n",
    "    if user == \"soft\":\n",
    "        online()\n",
    "    elif user == \"introduce yourself\":\n",
    "        online1()\n",
    "    elif user in ['music','play some music','play some melody','play a song','i want some music','song']:\n",
    "        media()\n",
    "    elif user in ['hey SOFT','wake up soft','wake up','oyee']:\n",
    "        getonline()\n",
    "    elif user == \"down\":\n",
    "        gooffline()\n",
    "    elif user in ['shutdown','see you tomorrow','bye soft','bye','ok bye','see you tomorrow soft','ok soft see you tomorrow','see you after some time','see you later','have some sleep soft']:\n",
    "        shutdown()\n",
    "    elif user in ['restart the system']:\n",
    "        restart()\n",
    "    elif user in ['hi','i','hey','hello']:\n",
    "        d = random.choice(['hey','hi','hello'])\n",
    "        speak(d)\n",
    "\n",
    "speak('hi.......what can i do for you? .......!!')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    r = sr.Recognizer()\n",
    "    \n",
    "    with sr.Microphone() as source:\n",
    "        while 1:\n",
    "            mainfunction()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
